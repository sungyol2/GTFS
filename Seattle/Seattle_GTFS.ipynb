{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "544de2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: shapely in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: pyproj in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: geopandas in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: rtree in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (from pyproj) (2025.8.3)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (from geopandas) (0.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (from geopandas) (25.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lette\\anaconda3\\envs\\momepy_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy shapely pyproj geopandas rtree tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36503210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy shapely pyproj geopandas rtree tqdm\n",
    "\n",
    "import zipfile, pandas as pd, numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import substring\n",
    "from pyproj import Geod\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08788e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# CONFIG — edit these first\n",
    "# -----------------------------\n",
    "GTFS_ZIP = \"gtfs_puget_sound_consolidated.zip\"  # your uploaded file name\n",
    "GTFS_BASE = \"\"    # inner folder name in the zip\n",
    "\n",
    "SERVICE_DATE = \"2025-09-10\"   # YYYY-MM-DD (weekday inside calendar range)\n",
    "TIME_STEP_SEC = 30            # sampling step (20–30s looks nice)\n",
    "TIME_START = \"06:00:00\"       # optional window start (set to None for full day)\n",
    "TIME_END   = \"10:00:00\"       # optional window end   (set to None for full day)\n",
    "\n",
    "# Keep only these route_types, or set to None for all\n",
    "# GTFS route_type: 0=Tram/LightRail, 1=Subway, 2=Rail, 3=Bus, 4=Ferry, 12=Monorail (sometimes 11/12 vary by feed)\n",
    "ROUTE_TYPES_INCLUDE = [0, 2, 3, 4]   # light rail/tram, rail (Sounder), bus, ferry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b13e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common dtype map for GTFS IDs (force to strings to avoid mixed-type warnings)\n",
    "ID_DTYPE = {\n",
    "    \"agency_id\": str,\n",
    "    \"route_id\": str,\n",
    "    \"trip_id\": str,\n",
    "    \"service_id\": str,\n",
    "    \"shape_id\": str,\n",
    "    \"stop_id\": str,\n",
    "    \"block_id\": str,\n",
    "}\n",
    "\n",
    "def _read_csv_from_zip(zf, name, usecols=None, extra_dtype=None):\n",
    "    # Merge the base ID dtype map with any file-specific overrides\n",
    "    dtype = dict(ID_DTYPE)\n",
    "    if extra_dtype:\n",
    "        dtype.update(extra_dtype)\n",
    "    return pd.read_csv(\n",
    "        zf.open(GTFS_BASE + name),\n",
    "        usecols=usecols,\n",
    "        dtype=dtype,\n",
    "        low_memory=False\n",
    "    )\n",
    "\n",
    "def service_ids_by_date(cal, cald, the_date: date):\n",
    "    \"\"\"Compute active service_ids for a given date using calendar + calendar_dates rules.\"\"\"\n",
    "    weekday = the_date.weekday()  # Mon=0 ... Sun=6\n",
    "    wkcols = [\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"sunday\"]\n",
    "    wkcol = wkcols[weekday]\n",
    "\n",
    "    active = cal[\n",
    "        (cal[\"start_date\"] <= pd.Timestamp(the_date)) &\n",
    "        (cal[\"end_date\"]   >= pd.Timestamp(the_date)) &\n",
    "        (cal[wkcol] == 1)\n",
    "    ][\"service_id\"].astype(str).tolist()\n",
    "    active = set(active)\n",
    "\n",
    "    if cald is not None and len(cald):\n",
    "        sel = cald[cald[\"date\"] == pd.Timestamp(the_date)]\n",
    "        for _, r in sel.iterrows():\n",
    "            sid = str(r[\"service_id\"])\n",
    "            if r[\"exception_type\"] == 1:   # added service\n",
    "                active.add(sid)\n",
    "            elif r[\"exception_type\"] == 2: # removed service\n",
    "                active.discard(sid)\n",
    "\n",
    "    return active\n",
    "\n",
    "# Load GTFS safely with explicit dtypes\n",
    "with zipfile.ZipFile(GTFS_ZIP) as zf:\n",
    "    routes = _read_csv_from_zip(\n",
    "        zf, \"routes.txt\",\n",
    "        usecols=[\"route_id\",\"route_type\",\"agency_id\"],\n",
    "        extra_dtype={\"route_type\": \"Int64\"}  # allow NA int\n",
    "    )\n",
    "    trips  = _read_csv_from_zip(\n",
    "        zf, \"trips.txt\",\n",
    "        usecols=[\"route_id\",\"trip_id\",\"service_id\",\"shape_id\",\"block_id\"]\n",
    "    )\n",
    "    # times as strings to preserve HH:MM:SS possibly >24h\n",
    "    stop_times = _read_csv_from_zip(\n",
    "        zf, \"stop_times.txt\",\n",
    "        extra_dtype={\n",
    "            \"arrival_time\": str,\n",
    "            \"departure_time\": str,\n",
    "            \"stop_sequence\": \"Int64\",\n",
    "            \"shape_dist_traveled\": \"float64\"\n",
    "        }\n",
    "    )\n",
    "    # shapes lat/lon strictly numeric; ids as strings\n",
    "    shapes = _read_csv_from_zip(\n",
    "        zf, \"shapes.txt\",\n",
    "        extra_dtype={\n",
    "            \"shape_pt_lat\": \"float64\",\n",
    "            \"shape_pt_lon\": \"float64\",\n",
    "            \"shape_pt_sequence\": \"Int64\"\n",
    "        }\n",
    "    )\n",
    "    cal = _read_csv_from_zip(zf, \"calendar.txt\")\n",
    "    cald = _read_csv_from_zip(zf, \"calendar_dates.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4017b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse calendar date fields\n",
    "for col in (\"start_date\", \"end_date\"):\n",
    "    cal[col] = pd.to_datetime(cal[col], format=\"%Y%m%d\")\n",
    "cald[\"date\"] = pd.to_datetime(cald[\"date\"], format=\"%Y%m%d\")\n",
    "\n",
    "# Pick service date and compute active services\n",
    "svc_dt = pd.to_datetime(SERVICE_DATE).date()\n",
    "active_sids = service_ids_by_date(cal, cald, svc_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f160911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter routes by route_type if requested\n",
    "if ROUTE_TYPES_INCLUDE is not None and \"route_type\" in routes.columns:\n",
    "    routes = routes[routes[\"route_type\"].isin(ROUTE_TYPES_INCLUDE)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b69801f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join trips with routes and keep only active services\n",
    "tr = trips.merge(routes[[\"route_id\",\"route_type\",\"agency_id\"]], on=\"route_id\", how=\"inner\")\n",
    "tr = tr[tr[\"service_id\"].astype(str).isin(active_sids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce01afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only needed stop_times columns\n",
    "keep_cols = [\"trip_id\",\"arrival_time\",\"departure_time\",\"stop_sequence\"]\n",
    "has_sdt = \"shape_dist_traveled\" in stop_times.columns\n",
    "if has_sdt:\n",
    "    keep_cols.append(\"shape_dist_traveled\")\n",
    "stop_times = stop_times[keep_cols].copy()\n",
    "stop_times[\"stop_sequence\"] = stop_times[\"stop_sequence\"].astype(\"Int64\")\n",
    "stop_times = stop_times.sort_values([\"trip_id\",\"stop_sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5004e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort shapes and build LineStrings\n",
    "shapes = shapes.sort_values([\"shape_id\",\"shape_pt_sequence\"])\n",
    "shape_lines = {}\n",
    "for sid, grp in shapes.groupby(\"shape_id\", sort=False):\n",
    "    coords = grp[[\"shape_pt_lon\",\"shape_pt_lat\"]].to_numpy()\n",
    "    # (x, y) = (lon, lat)\n",
    "    shape_lines[str(sid)] = LineString(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5025c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute geodesic length for each shape (meters)\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "def geod_length_m(line: LineString) -> float:\n",
    "    lons, lats = line.xy\n",
    "    if len(lons) < 2:\n",
    "        return 0.0\n",
    "    return sum(geod.line_length([lons[i], lons[i+1]], [lats[i], lats[i+1]]) for i in range(len(lons)-1))\n",
    "\n",
    "shape_lengths = {sid: geod_length_m(ln) for sid, ln in shape_lines.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a387d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time parsing helpers\n",
    "def to_timedelta(hms: str):\n",
    "    # Robust to strings like \"25:10:00\"\n",
    "    h, m, s = [int(x) for x in hms.split(\":\")]\n",
    "    return timedelta(hours=h, minutes=m, seconds=s)\n",
    "\n",
    "window_start = to_timedelta(TIME_START) if TIME_START else None\n",
    "window_end   = to_timedelta(TIME_END)   if TIME_END else None\n",
    "\n",
    "def interpolate_trip(trip_id: str, shape_id: str, times_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Interpolate positions for a single trip into (timestamp, lon, lat) using integer seconds.\"\"\"\n",
    "    shape_id = str(shape_id)\n",
    "    if shape_id not in shape_lines:\n",
    "        return pd.DataFrame()\n",
    "    line = shape_lines[shape_id]\n",
    "    if line.length == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = times_df.sort_values(\"stop_sequence\").copy()\n",
    "\n",
    "    # Build time column (prefer departure_time), keep only valid HH:MM:SS rows\n",
    "    use_dep = df[\"departure_time\"].notna()\n",
    "    df[\"t_str\"] = df[\"departure_time\"].where(use_dep, df[\"arrival_time\"])\n",
    "    df = df[df[\"t_str\"].notna()].copy()\n",
    "    mask = df[\"t_str\"].astype(str).str.match(r\"^\\d{1,2}:\\d{2}:\\d{2}$\")\n",
    "    df = df[mask].copy()\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Convert \"HH:MM:SS\" -> integer seconds (supports HH >= 24)\n",
    "    def hms_to_sec(s: str) -> int:\n",
    "        h, m, sec = map(int, s.split(\":\"))\n",
    "        return h*3600 + m*60 + sec\n",
    "\n",
    "    df[\"t_sec\"] = df[\"t_str\"].astype(str).apply(hms_to_sec)\n",
    "\n",
    "    # Fractions along the shape\n",
    "    if has_sdt and df.get(\"shape_dist_traveled\") is not None:\n",
    "        L_m = shape_lengths.get(shape_id, None)\n",
    "        if L_m and L_m > 0 and df[\"shape_dist_traveled\"].notna().any():\n",
    "            df[\"f\"] = df[\"shape_dist_traveled\"].astype(float) / L_m\n",
    "            df[\"f\"] = df[\"f\"].clip(0, 1)\n",
    "        else:\n",
    "            n = len(df)\n",
    "            df[\"f\"] = np.linspace(0, 1, n)\n",
    "    else:\n",
    "        n = len(df)\n",
    "        df[\"f\"] = np.linspace(0, 1, n)\n",
    "\n",
    "    # Determine interpolation window in seconds\n",
    "    t0_sec = int(df[\"t_sec\"].iloc[0])\n",
    "    tN_sec = int(df[\"t_sec\"].iloc[-1])\n",
    "\n",
    "    def to_sec_or_none(hms):\n",
    "        if hms is None: return None\n",
    "        h, m, s = map(int, hms.split(\":\"))\n",
    "        return h*3600 + m*60 + s\n",
    "\n",
    "    ws_sec = to_sec_or_none(TIME_START)\n",
    "    we_sec = to_sec_or_none(TIME_END)\n",
    "\n",
    "    start_sec = ws_sec if ws_sec is not None else t0_sec\n",
    "    end_sec   = we_sec if we_sec is not None else tN_sec\n",
    "    # Clamp to trip bounds\n",
    "    start_sec = max(t0_sec, start_sec)\n",
    "    end_sec   = min(tN_sec, end_sec)\n",
    "    if end_sec <= start_sec:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Ensure monotonic times (rare, but guard against duplicates)\n",
    "    df = df.sort_values(\"t_sec\").drop_duplicates(subset=[\"t_sec\"])\n",
    "    T_sec = df[\"t_sec\"].to_numpy()\n",
    "    F = df[\"f\"].to_numpy()\n",
    "\n",
    "    # Sample timestamps (integer seconds)\n",
    "    ts_sec = np.arange(start_sec, end_sec + 1, TIME_STEP_SEC, dtype=int)\n",
    "\n",
    "    rows = []\n",
    "    for tt in ts_sec:\n",
    "        # find segment index\n",
    "        j = np.searchsorted(T_sec, tt) - 1\n",
    "        if j < 0:\n",
    "            j = 0\n",
    "        if j >= len(T_sec) - 1:\n",
    "            j = len(T_sec) - 2\n",
    "        t1, t2 = T_sec[j], T_sec[j+1]\n",
    "        f1, f2 = F[j], F[j+1]\n",
    "        if t2 == t1:\n",
    "            f = float(f2)\n",
    "        else:\n",
    "            f = float(f1 + (f2 - f1) * ((tt - t1) / (t2 - t1)))\n",
    "        f = max(0.0, min(1.0, f))\n",
    "        sub = substring(line, 0, f, normalized=True)\n",
    "        x, y = sub.coords[-1]\n",
    "        rows.append((tt, x, y))\n",
    "\n",
    "    out = pd.DataFrame(rows, columns=[\"t_sec\", \"lon\", \"lat\"])\n",
    "    out[\"trip_id\"] = str(trip_id)\n",
    "    out[\"shape_id\"] = shape_id\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89607484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build trip→shape metadata\n",
    "tr_sel = tr.dropna(subset=[\"trip_id\",\"shape_id\"]).copy()\n",
    "tr_sel[\"trip_id\"] = tr_sel[\"trip_id\"].astype(str)\n",
    "tr_sel[\"shape_id\"] = tr_sel[\"shape_id\"].astype(str)\n",
    "trip_meta = tr_sel.set_index(\"trip_id\")[[\"route_id\",\"route_type\",\"agency_id\",\"shape_id\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aee078eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpolating trips: 100%|██████████| 129683/129683 [04:42<00:00, 459.76it/s] \n"
     ]
    }
   ],
   "source": [
    "# Interpolate all trips\n",
    "points = []\n",
    "for trip_id, g in tqdm(stop_times.groupby(\"trip_id\"), desc=\"Interpolating trips\"):\n",
    "    tid = str(trip_id)\n",
    "    if tid not in trip_meta.index:\n",
    "        continue\n",
    "    meta = trip_meta.loc[tid]\n",
    "    shp = meta[\"shape_id\"]\n",
    "    dfp = interpolate_trip(tid, shp, g)\n",
    "    if len(dfp):\n",
    "        dfp[\"route_id\"]   = meta[\"route_id\"]\n",
    "        dfp[\"route_type\"] = meta[\"route_type\"]\n",
    "        dfp[\"agency_id\"]  = meta[\"agency_id\"]\n",
    "        points.append(dfp)\n",
    "\n",
    "if not points:\n",
    "    raise SystemExit(\"No points generated. Check SERVICE_DATE and time window against calendar.\")\n",
    "\n",
    "pts = pd.concat(points, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8beeaa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 419,118 points to seattle_transit_points.csv\n",
      "   t_sec         lon        lat  trip_id    shape_id route_id  route_type  \\\n",
      "0  32400 -122.512384  47.165187  1006020  shp-202-04      202           3   \n",
      "1  32430 -122.509473  47.165168  1006020  shp-202-04      202           3   \n",
      "2  32460 -122.507542  47.166495  1006020  shp-202-04      202           3   \n",
      "3  32490 -122.506571  47.168621  1006020  shp-202-04      202           3   \n",
      "4  32520 -122.505770  47.170792  1006020  shp-202-04      202           3   \n",
      "\n",
      "  agency_id            datetime  \n",
      "0         3 2025-09-10 09:00:00  \n",
      "1         3 2025-09-10 09:00:30  \n",
      "2         3 2025-09-10 09:01:00  \n",
      "3         3 2025-09-10 09:01:30  \n",
      "4         3 2025-09-10 09:02:00  \n"
     ]
    }
   ],
   "source": [
    "# Compose absolute datetime for QGIS Time Manager\n",
    "service_day = pd.Timestamp(SERVICE_DATE)\n",
    "# if interpolate_trip outputs 't_sec' instead of 't'\n",
    "pts[\"datetime\"] = service_day + pd.to_timedelta(pts[\"t_sec\"], unit=\"s\")\n",
    "\n",
    "# Save CSV\n",
    "OUT_CSV = \"seattle_transit_points.csv\"\n",
    "pts.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Wrote {len(pts):,} points to {OUT_CSV}\")\n",
    "print(pts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f3aae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lette\\AppData\\Local\\Temp\\ipykernel_449672\\2359796962.py:3: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"seattle_transit_points.csv\", parse_dates=[\"datetime\"])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"seattle_transit_points.csv\", parse_dates=[\"datetime\"])\n",
    "# Each point will remain visible for 2 minutes\n",
    "df[\"end_datetime\"] = df[\"datetime\"] + pd.to_timedelta(2, unit=\"m\")\n",
    "df.to_csv(\"seattle_transit_points_with_end.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b9c99a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lette\\AppData\\Local\\Temp\\ipykernel_449672\\79139674.py:8: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(IN_CSV, parse_dates=[\"datetime\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 static trips\n",
      "Saved cleaned file with 412,782 points → seattle_transit_points_moving.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input + output file paths\n",
    "IN_CSV = \"seattle_transit_points_with_end.csv\"            # or \"seattle_transit_points_with_end.csv\"\n",
    "OUT_CSV = \"seattle_transit_points_moving.csv\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(IN_CSV, parse_dates=[\"datetime\"])\n",
    "\n",
    "# Find trips that never change position\n",
    "static_trips = (\n",
    "    df.groupby(\"trip_id\")\n",
    "      .agg(lon_unique=(\"lon\", \"nunique\"),\n",
    "           lat_unique=(\"lat\", \"nunique\"))\n",
    ")\n",
    "static_trips = static_trips[\n",
    "    (static_trips[\"lon_unique\"] == 1) & (static_trips[\"lat_unique\"] == 1)\n",
    "]\n",
    "\n",
    "print(f\"Found {len(static_trips)} static trips\")\n",
    "\n",
    "# Filter them out\n",
    "df_clean = df[~df[\"trip_id\"].isin(static_trips.index)]\n",
    "\n",
    "# Save\n",
    "df_clean.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved cleaned file with {len(df_clean):,} points → {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085f76d",
   "metadata": {},
   "source": [
    "##Charting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momepy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
